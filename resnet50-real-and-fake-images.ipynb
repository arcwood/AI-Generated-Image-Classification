{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-01T12:58:25.091287Z","iopub.execute_input":"2023-07-01T12:58:25.092103Z","iopub.status.idle":"2023-07-01T12:58:25.098511Z","shell.execute_reply.started":"2023-07-01T12:58:25.092067Z","shell.execute_reply":"2023-07-01T12:58:25.097542Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Input and Preprocessing of Images","metadata":{}},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/140k-real-and-fake-faces/train.csv\"\ndf = pd.read_csv(dataset_path)\ndataset_path = '/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\nimage_dir = os.path.join(dataset_path, 'train')\nreal_dir = os.path.join(image_dir, 'real')\nfake_dir = os.path.join(image_dir, 'fake')\nimage_paths = df['path'].apply(lambda x: os.path.join(real_dir if 'real' in x else fake_dir, x.split('/')[-1]))\nlabels = df['label'].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T12:58:27.459098Z","iopub.execute_input":"2023-07-01T12:58:27.459507Z","iopub.status.idle":"2023-07-01T12:58:28.110327Z","shell.execute_reply.started":"2023-07-01T12:58:27.459476Z","shell.execute_reply":"2023-07-01T12:58:28.109187Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Reducing the input data to 10000 images\nrandom_indices = np.random.choice(len(image_paths), size=int(0.1 * len(image_paths)), replace=False)\nimage_paths = image_paths[random_indices]\nlabels = np.array(labels)[random_indices]","metadata":{"execution":{"iopub.status.busy":"2023-07-01T12:58:29.768646Z","iopub.execute_input":"2023-07-01T12:58:29.769076Z","iopub.status.idle":"2023-07-01T12:58:29.801051Z","shell.execute_reply.started":"2023-07-01T12:58:29.769043Z","shell.execute_reply":"2023-07-01T12:58:29.799662Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess the images\nimages = []\nfor img_path in image_paths:\n    img = Image.open(img_path)\n    img = img.resize((224, 224))  # Resize the image if needed\n    img_array = np.array(img)  # Convert the image to a NumPy array\n    images.append(img_array)\n\nimages = np.stack(images)  # Convert the list of arrays to a single NumPy array\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T12:58:30.773353Z","iopub.execute_input":"2023-07-01T12:58:30.773781Z","iopub.status.idle":"2023-07-01T13:00:16.681827Z","shell.execute_reply.started":"2023-07-01T12:58:30.773747Z","shell.execute_reply":"2023-07-01T13:00:16.680316Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Convert y_train and y_test to categorical (one-hot encode)\nnum_classes = 2 \ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T13:00:16.684081Z","iopub.execute_input":"2023-07-01T13:00:16.684464Z","iopub.status.idle":"2023-07-01T13:00:16.690192Z","shell.execute_reply.started":"2023-07-01T13:00:16.684432Z","shell.execute_reply":"2023-07-01T13:00:16.689155Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Resnet50 Model","metadata":{}},{"cell_type":"code","source":"base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2023-07-01T13:00:16.691370Z","iopub.execute_input":"2023-07-01T13:00:16.692453Z","iopub.status.idle":"2023-07-01T13:00:18.948135Z","shell.execute_reply.started":"2023-07-01T13:00:16.692418Z","shell.execute_reply":"2023-07-01T13:00:18.946874Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Custom Layers on top of Resnet50\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(256, activation='relu')(x)\npredictions = Dense(num_classes, activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T13:00:18.951340Z","iopub.execute_input":"2023-07-01T13:00:18.951906Z","iopub.status.idle":"2023-07-01T13:00:18.991882Z","shell.execute_reply.started":"2023-07-01T13:00:18.951862Z","shell.execute_reply":"2023-07-01T13:00:18.990673Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=base_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T13:00:18.993427Z","iopub.execute_input":"2023-07-01T13:00:18.993921Z","iopub.status.idle":"2023-07-01T13:00:19.017158Z","shell.execute_reply.started":"2023-07-01T13:00:18.993878Z","shell.execute_reply":"2023-07-01T13:00:19.015851Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-01T13:00:19.018690Z","iopub.execute_input":"2023-07-01T13:00:19.019116Z","iopub.status.idle":"2023-07-01T13:00:19.037052Z","shell.execute_reply.started":"2023-07-01T13:00:19.019071Z","shell.execute_reply":"2023-07-01T13:00:19.035582Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Training the model\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-01T13:00:19.038294Z","iopub.execute_input":"2023-07-01T13:00:19.038631Z","iopub.status.idle":"2023-07-01T21:47:50.183101Z","shell.execute_reply.started":"2023-07-01T13:00:19.038602Z","shell.execute_reply":"2023-07-01T21:47:50.181147Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/10\n250/250 [==============================] - 3231s 13s/step - loss: 0.4886 - accuracy: 0.7661 - val_loss: 1.1265 - val_accuracy: 0.6870\nEpoch 2/10\n250/250 [==============================] - 3239s 13s/step - loss: 0.2653 - accuracy: 0.8904 - val_loss: 0.6481 - val_accuracy: 0.7140\nEpoch 3/10\n250/250 [==============================] - 3238s 13s/step - loss: 0.1791 - accuracy: 0.9320 - val_loss: 1.9359 - val_accuracy: 0.5455\nEpoch 4/10\n250/250 [==============================] - 3234s 13s/step - loss: 0.1299 - accuracy: 0.9516 - val_loss: 0.8760 - val_accuracy: 0.7820\nEpoch 5/10\n250/250 [==============================] - 3144s 13s/step - loss: 0.1050 - accuracy: 0.9621 - val_loss: 0.4663 - val_accuracy: 0.8510\nEpoch 6/10\n250/250 [==============================] - 3158s 13s/step - loss: 0.0885 - accuracy: 0.9664 - val_loss: 0.3325 - val_accuracy: 0.8600\nEpoch 7/10\n250/250 [==============================] - 3079s 12s/step - loss: 0.0651 - accuracy: 0.9758 - val_loss: 0.3125 - val_accuracy: 0.8550\nEpoch 8/10\n250/250 [==============================] - 3090s 12s/step - loss: 0.0581 - accuracy: 0.9779 - val_loss: 0.8104 - val_accuracy: 0.8395\nEpoch 9/10\n250/250 [==============================] - 3137s 13s/step - loss: 0.0521 - accuracy: 0.9814 - val_loss: 0.4077 - val_accuracy: 0.8600\nEpoch 10/10\n250/250 [==============================] - 3101s 12s/step - loss: 0.0450 - accuracy: 0.9843 - val_loss: 0.4053 - val_accuracy: 0.8685\n","output_type":"stream"}]},{"cell_type":"code","source":"# Result\ntest_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T21:47:50.187110Z","iopub.execute_input":"2023-07-01T21:47:50.187598Z","iopub.status.idle":"2023-07-01T21:50:44.446200Z","shell.execute_reply.started":"2023-07-01T21:47:50.187549Z","shell.execute_reply":"2023-07-01T21:50:44.445086Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"63/63 - 174s - loss: 0.4053 - accuracy: 0.8685 - 174s/epoch - 3s/step\nTest Loss: 0.40532851219177246\nTest Accuracy: 0.8684999942779541\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing on 1000 new images","metadata":{}},{"cell_type":"code","source":"test_dataset_path = \"/kaggle/input/140k-real-and-fake-faces/test.csv\"\ntest_df = pd.read_csv(test_dataset_path)\ntest_data_path = '/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\nimage_dir = os.path.join(test_data_path, 'test')\ntest_real_dir = os.path.join(image_dir, 'real')\ntest_fake_dir = os.path.join(image_dir, 'fake')\ntest_image_paths = test_df['path'].apply(lambda x: os.path.join(test_real_dir if 'real' in x else test_fake_dir, x.split('/')[-1]))\nlabels = test_df['label'].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T22:13:00.370907Z","iopub.execute_input":"2023-07-01T22:13:00.372140Z","iopub.status.idle":"2023-07-01T22:13:00.509827Z","shell.execute_reply.started":"2023-07-01T22:13:00.372103Z","shell.execute_reply":"2023-07-01T22:13:00.508721Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Reducing input data to 1000 images\nrandom_indices = np.random.choice(len(test_image_paths), size=int(0.01 * len(test_image_paths)), replace=False)\ntest_image_paths = test_image_paths[random_indices]\nlabels = np.array(labels)[random_indices]","metadata":{"execution":{"iopub.status.busy":"2023-07-01T22:13:04.242712Z","iopub.execute_input":"2023-07-01T22:13:04.243163Z","iopub.status.idle":"2023-07-01T22:13:04.255568Z","shell.execute_reply.started":"2023-07-01T22:13:04.243129Z","shell.execute_reply":"2023-07-01T22:13:04.254361Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess the images\ntest_images = []\nfor img_path in test_image_paths:\n    img = Image.open(img_path)\n    img = img.resize((224, 224))  # Resize the image if needed\n    img_array = np.array(img)  # Convert the image to a NumPy array\n    test_images.append(img_array)\n\ntest_images = np.stack(test_images)  # Convert the list of arrays to a single NumPy array\n\nx_test = test_images\ny_test = labels\ny_test = to_categorical(y_test, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T22:14:04.226415Z","iopub.execute_input":"2023-07-01T22:14:04.227647Z","iopub.status.idle":"2023-07-01T22:14:04.894327Z","shell.execute_reply.started":"2023-07-01T22:14:04.227598Z","shell.execute_reply":"2023-07-01T22:14:04.893347Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Result\ntest_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T22:14:07.542405Z","iopub.execute_input":"2023-07-01T22:14:07.542828Z","iopub.status.idle":"2023-07-01T22:14:25.556808Z","shell.execute_reply.started":"2023-07-01T22:14:07.542781Z","shell.execute_reply":"2023-07-01T22:14:25.555676Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"7/7 - 18s - loss: 0.4811 - accuracy: 0.8500 - 18s/epoch - 3s/step\nTest Loss: 0.4810963571071625\nTest Accuracy: 0.8500000238418579\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}